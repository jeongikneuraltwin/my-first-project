# NEURALTWIN 1주 집중 테스트 계획서

- **버전**: v2.1 (KR)  

---

## 0. 개요

### 0.1 목적

목표는 현재 아키텍처가 치명적인 기능 장애나 데이터 정합성 문제 없이 **엔드투엔드로 정상 동작**하는지, 각 레이어별로 체계적으로 검증하는 것이다.

테스트 대상 레이어는 다음과 같다.

- 레이어 1 – Data Management & Ontology/Graph  
- 레이어 2 – Store Analysis & Analytics  
- 레이어 3 – Simulation & AI  
- 레이어 4 – Digital Twin 3D  
- 레이어 5 – 공통 레이어 (Authentication, Row Level Security, Error Handling, Basic Performance)

### 0.2 테스트 접근 방식

각 레이어별로 다음 항목을 정의한다.

1. 목적 및 범위  
2. 테스트 대상 영역 (기능 리스트)  
3. 테스트 타입 및 전략  
4. 테스트 시나리오  
   - 목적  
   - 사전 조건  
   - 절차 (Step-by-step)  
   - 통과 기준  
5. 레이어 전체 통과/실패 기준  
6. 버그 분류 및 예상 핫스팟  
7. 비고  


---

## 1. 레이어 1 – Data Management & Ontology/Graph

### 1.1 목적 및 범위

#### 목적

- CSV/Excel, WiFi 로그, 외부 데이터 등 **모든 인입 데이터**가  
  `user_data_imports → Ontology 스키마 적용 → graph_entities / graph_relations`  
  파이프라인을 통해 데이터 손실·왜곡 없이 처리되는지 검증한다.
- `/schema-builder` 에서 정의한 **엔티티 타입 및 관계 타입 변경**이  
  실제 Graph 데이터 및 `/graph-analysis` 화면에 올바르게 반영되는지 검증한다.

#### 범위 (포함)

- 페이지
  - `/data-import` (통합 데이터 관리 페이지)
  - `/schema-builder`
  - `/graph-analysis`
  - `/bigdata-api` (외부 소스/스케줄/로그 조회)
- 테이블
  - `user_data_imports`
  - `ontology_entity_types`, `ontology_relation_types`
  - `graph_entities`, `graph_relations`
  - `external_data_sources`, `data_sync_schedules`, `data_sync_logs`
- Edge Functions
  - `import-with-ontology`
  - `process-wifi-data` (데이터 흐름 관점)
  - 기타 외부 동기화 관련 함수

#### 범위 (제외)

- KPI 집계 로직 상세
- Simulation 및 3D 시각화 상세 (각각 별도 레이어에서 검증)

### 1.2 테스트 대상 영역

| ID     | 영역                         | 설명                                               | 중요도   |
|--------|------------------------------|----------------------------------------------------|----------|
| L1-F01 | Unified Data Import          | CSV/Excel 업로드, 타입 선택, 매핑, 검증           | Critical |
| L1-F02 | Ontology Entity Types        | 엔티티 타입 정의 및 수정                          | High     |
| L1-F03 | Ontology Relation Types      | 관계 타입 정의 및 수정                            | High     |
| L1-F04 | Ontology-Import Mapping      | 스키마 기반 자동/수동 매핑                        | Critical |
| L1-F05 | Graph Entities 생성          | `graph_entities` 레코드 생성/업데이트            | Critical |
| L1-F06 | Graph Relations 생성         | `graph_relations` 레코드 생성/업데이트           | Critical |
| L1-F07 | Graph Analysis View          | 엔티티/관계 시각화 및 필터링                      | High     |
| L1-F08 | External Data Management     | 외부 소스/스케줄/로그 조회                        | Medium   |

### 1.3 테스트 타입 및 전략

- **기능 테스트**  
  각 페이지/폼/버튼이 설계된 대로 동작하는지 검증한다.

- **데이터 정합성 테스트**  
  업로드한 데이터가 기대한 엔티티/관계 구조로 생성되고,  
  누락/중복/오매핑 없이 `graph_entities`, `graph_relations` 에 반영되는지 검증한다.

- **엣지/네거티브 테스트**  
  필수 컬럼 누락, 형식 오류, 빈 파일 등 비정상 CSV 입력 시의 동작을 검증한다.

- **스키마 변경 테스트**  
  `ontology_entity_types` / `ontology_relation_types` 변경 후 동일 데이터를 재임포트했을 때 결과가 올바르게 반영되는지 검증한다.

#### 용어 주석

- **Edge Function 타임아웃**  
  Supabase Edge Function 이 최대 허용 실행 시간을 초과하여 타임아웃 에러로 종료되는 경우를 의미한다.

- **연결 깊이 (N-hop)**  
  그래프에서 시작 노드로부터 몇 단계의 관계를 따라가는지를 나타내는 개념으로,  
  1-hop 은 직접 연결된 노드, 2-hop 은 중간 노드 한 개를 거쳐 연결된 노드를 의미한다.

---

### 1.4 테스트 시나리오

#### SCN-L1-01 – 모든 데이터 타입 기본 임포트 플로우

**목적**  
지원하는 각 데이터 타입이 “정상 CSV” 기준으로 업로드되었을 때,  
UI 업로드 → `user_data_imports` → Ontology 매핑 → `graph_entities` / `graph_relations` → `/graph-analysis`  
까지 전체 플로우가 정상 동작하는지 검증한다.

**사전 조건**

- 테스트 계정 A  
- 계정 A 에 속한 매장 S1  
- 소량 샘플 CSV (각 10–50행 수준)
  - `products_valid.csv`
  - `customers_valid.csv`
  - `sales_valid.csv`
  - `visits_valid.csv`
  - `wifi_valid.csv`
  - `inventory_valid.csv`
- `/schema-builder` 에서 다음과 같은 스키마 정의
  - 엔티티 타입: `Product`, `Customer`, `Visit`, `Sale`, `Zone` 등
  - 관계 타입: `PURCHASED (Customer→Product)`, `VISITED (Customer→Zone)` 등

**절차**

각 데이터 타입에 대해 아래 1)~7) 단계를 반복 수행한다.

1. `/data-import` 페이지 접속  
2. “Data Type” 드롭다운에서 해당 타입 선택 (예: `products`)  
3. 해당 CSV 파일 업로드 (예: `products_valid.csv`)  
4. 매핑 UI에서 필수 필드(`sku`, `name`, `price` 등)가 올바른 컬럼과 연결되어 있는지 확인하고, 필요 시 수동으로 매핑 수정  
5. 임포트 실행 버튼 클릭  
6. 완료 후 다음을 확인  
   - UI 상에서 성공 상태 표시 (성공 메시지/배지 등)  
   - Supabase `user_data_imports` 조회  
     - 선택한 `data_type` 에 대한 레코드 존재  
     - `row_count` 값이 실제 CSV 데이터 행 수와 일치  
   - `graph_entities` / `graph_relations` 조회  
     - 설계한 샘플 데이터 구조에 맞게 엔티티/관계가 생성되었는지 확인  
7. `/graph-analysis` 접속  
   - 해당 엔티티 타입(예: Product)으로 필터링 또는 검색  
   - 노드가 그래프 상에 표시되는지 확인  

**통과 기준**

- 각 데이터 타입별로 다음을 만족한다.
  - `user_data_imports` 에 정확한 `row_count` 를 가진 레코드가 생성된다.  
  - `graph_entities` / `graph_relations` 에 예상 수량 및 타입의 엔티티/관계가 생성된다.  
  - `/graph-analysis` 에서 해당 노드들이 오류 없이 표시된다.  
- 플로우 중 HTTP 500, 처리 중단 등의 치명적 오류가 발생하지 않는다.

---

#### SCN-L1-02 – 잘못된/부분 손상 CSV 처리

**목적**  
비정상 CSV 파일 업로드 시 애플리케이션이 비정상 종료되지 않고,  
이유를 이해할 수 있는 오류 메시지를 UI 및 `user_data_imports` 에 적절히 기록하는지 검증한다.

**사전 조건**

다음과 같은 CSV 파일을 준비한다.

- `products_missing_required.csv`  
  (예: `sku` 등 필수 컬럼이 하나 이상 누락된 파일)
- `products_wrong_type.csv`  
  (숫자 컬럼에 문자열, 잘못된 형식 데이터 포함)
- `sales_bad_date.csv`  
  (날짜 포맷이 잘못되었거나 여러 포맷이 섞인 파일)
- `empty.csv`  
  (완전히 비어 있거나 헤더만 존재하는 파일)

**절차**

각 비정상 CSV 케이스마다 아래 절차를 수행한다.

1. `/data-import` 접속  
2. 해당 데이터 타입 선택 (예: `products`)  
3. 비정상 CSV 파일 업로드  
4. 매핑 UI에서 가능한 한 정상처럼 매핑 수행  
5. 임포트 실행  
6. 다음 항목을 확인  
   - 화면에 오류 메시지 또는 경고가 표시되는지 확인  
   - 메시지 내용이 “어떤 이유로 파일을 처리할 수 없는지” 최소한의 정보를 제공하는지 확인  
     (예: “필수 컬럼 `sku` 가 누락되었습니다”)  
7. `user_data_imports` 조회  
   - 시도한 임포트에 대한 레코드 존재  
   - `status` 가 실패 상태(예: `failed`)로 기록  
   - `row_count` 값이 0 또는 설계에 따른 처리 행 수로 일관되게 기록  

**통과 기준**

- 어떤 비정상 CSV에 대해서도 애플리케이션이 크래시 또는 무한 로딩 상태에 빠지지 않는다.  
- 500 에러 페이지나 스택트레이스 등의 내부 디버깅 정보가 사용자에게 노출되지 않는다.  
- 사용자 입장에서 파일이 처리되지 않은 이유를 이해할 수 있는 수준의 오류 메시지가 제공된다.  
- `user_data_imports` 는 실패 상태를 정확히 기록하고, 성공으로 표시하지 않는다.

---

#### SCN-L1-03 – Ontology 스키마 변경 후 재임포트

**목적**  
Ontology 엔티티 타입을 변경한 이후 동일 CSV를 재임포트했을 때,  
Graph 엔티티 구조에 해당 변경 사항이 올바르게 반영되는지 검증한다.

**사전 조건**

- `products_valid.csv` 준비  
- 초기 Ontology 스키마  
  - Product 엔티티 타입: `sku`, `name`, `price`, `category` 속성만 존재  
- 변경 후 Ontology 스키마 (시나리오 중간에 적용)  
  - Product 엔티티 타입에 `brand` 속성 추가  

**절차**

1. `/schema-builder` 접속 후 Product 엔티티 타입에 `brand` 속성이 존재하지 않는 상태임을 확인  
2. `/data-import` 에서 `Data Type = products` 로 설정 후  
   `products_valid.csv` 임포트 수행 (SCN-L1-01 절차 참조)  
3. 임포트 완료 후 `graph_entities` 조회  
   - Product 엔티티 `properties` JSON 에 `sku`, `name`, `price`, `category` 만 포함되는지 확인  
4. `/schema-builder` 로 이동하여 Product 엔티티 타입에 `brand` 속성 추가 후 저장  
5. 동일 `products_valid.csv` 를 다시 `/data-import` 에서 임포트  
6. 재임포트 후 `graph_entities` 조회  
   - 새로 생성된 Product 엔티티 `properties` JSON 에 `brand` 필드가 추가되었고 값이 올바르게 들어 있는지 확인  
7. `/graph-analysis` 에서 Product 노드 선택 시 속성 패널에 `brand` 값이 노출되는지 확인  

**통과 기준**

- 스키마 변경 과정에서 오류가 발생하지 않는다.  
- 재임포트된 Product 엔티티에 `brand` 속성이 추가되어 있다.  
- `/graph-analysis` 화면에서 `brand` 속성이 확인 가능하다.

---

#### SCN-L1-04 – Graph Analysis 연결 관계 검증

**목적**  
`/graph-analysis` 화면에서 특정 노드 선택 시  
직접 연결(1-hop) 및 간접 연결(2-hop)의 표시가 `graph_relations` 구조와 일치하는지 검증한다.

**사전 조건**

소규모 테스트용 그래프 데이터를 준비한다.

- Customer: `C1`  
- Products: `P1` (셔츠), `P2` (바지)  
- Zones: `Z1` (입구), `Z2` (메인존)  
- Relations
  - `C1 VISITED Z1`
  - `C1 PURCHASED P1`
  - `Z1 HAS_PRODUCT P1`
  - `Z2 HAS_PRODUCT P2`

위 데이터는 CSV 임포트 또는 `graph_entities` / `graph_relations` 직접 insert 로 구성할 수 있다.

**절차**

1. `/graph-analysis` 접속  
2. 스토어 S1 및 전체 엔티티 타입이 표시되도록 필터 설정  
3. 그래프에서 Customer `C1` 노드를 선택  
4. 1-hop (직접 연결) 확인  
   - `Z1` (방문 존)이 `C1` 과 직접 연결  
   - `P1` (구매 상품)이 `C1` 과 직접 연결  
5. 연결 깊이(Depth) 설정이 존재하는 경우  
   - 깊이 1로 설정 시 `C1` 주변에 `Z1`, `P1` 만 표시되는지 확인  
   - 깊이 2로 설정 시, 중간 노드를 거쳐 도달 가능한 추가 노드가 표시되는지 확인  
6. 타입 필터 적용  
   - Product만 표시 시 `P1` 만 남는지 확인  
   - Zone만 표시 시 `Z1` 만 남는지 확인  

**통과 기준**

- `C1` 기준 직접/간접 연결 관계가 준비된 테스트 그래프 구조와 일치한다.  
- 타입 및 깊이 필터 조합 사용 시 결과가 논리적으로 일관된다.

---

#### SCN-L1-05 – 외부 데이터 소스/스케줄/로그 표시

**목적**  
외부 데이터 소스 설정, 스케줄, 로그 정보가 UI에서 정상적으로 표시되고,  
실패 상태 또한 UI에서 확인 가능한지 검증한다.

**사전 조건**

다음 테이블에 샘플 레코드를 수동 또는 도구를 통해 생성한다.

- `external_data_sources` (예: `WeatherAPI`, `EconomicAPI` 등 명칭)  
- `data_sync_schedules` (예: 매일 실행되는 cron 표현식)  
- `data_sync_logs` (성공/실패 로그 최소 1~2건, 각 스케줄과 연계)

**절차**

1. `/bigdata-api` 페이지 접속  
2. `external_data_sources` 목록에서 각 소스가 이름/타입과 함께 표시되는지 확인  
3. 소스를 선택하여 연결된 `data_sync_schedules` 가  
   - 스케줄 이름  
   - cron 표현식  
   - 활성 여부  
   - 마지막 실행 시각  
   - 다음 실행 예정 시각  
   과 함께 표시되는지 확인  
4. 로그 보기 기능이 있는 경우  
   - 해당 스케줄의 `data_sync_logs` 목록을 확인  
   - 성공/실패 로그가 시간과 함께 표시되는지 확인  
   - 실패 로그에 대해 최소한의 오류 설명(메시지)이 표시되는지 확인  

**통과 기준**

- 소스/스케줄/로그 정보가 DB 내용과 일관되게 UI에 표시된다.  
- 실패 로그가 존재하더라도 페이지가 깨지지 않고, 읽을 수 있는 형태로 표현된다.

---

### 1.5 레이어 1 통과/실패 기준

- 각 주요 데이터 타입에 대해 SCN-L1-01 플로우가 치명적 오류 없이 수행된다.  
- 비정상 CSV에 대해 SCN-L1-02 기준을 만족한다.  
- Ontology 스키마 변경 후 재임포트 시 파이프라인이 깨지지 않고 결과가 반영된다. (SCN-L1-03)  
- Graph Analysis 가 테스트 그래프 구조를 정확히 반영한다. (SCN-L1-04)  
- 외부 데이터 설정 화면이 안정적으로 동작한다. (SCN-L1-05)

### 1.6 버그 분류 및 예상 핫스팟

#### Severity 정의

- **S1 (Blocker)**  
  핵심 데이터 타입에 대해 임포트 또는 Graph 생성이 불가능한 수준.
- **S2 (Major)**  
  데이터는 생성되지만 매핑 오류/누락으로 인해 분석·시뮬레이션 결과를 심각하게 왜곡하는 수준.
- **S3 (Minor)**  
  상태/로그/UI 표시는 부정확하지만 기능 플로우는 동작하는 수준.
- **S4 (Trivial)**  
  문구, 레이아웃 등 시각적인 경미한 문제.

#### 예상 핫스팟

- CSV 파싱  
  인코딩, 날짜 포맷, 숫자/문자 혼합 등으로 인한 오류.
- Ontology 매핑  
  필수 필드 미매핑, 잘못된 엔티티 타입 매핑.
- Graph 생성  
  `entity_type_id`, `relation_type_id` 잘못 참조.
- Edge Function 타임아웃  
  대용량 CSV 또는 지연이 큰 외부 서비스 호출 시 발생 가능.  
  타임아웃 발생 시에도 UI와 로그가 안정적으로 동작하는지 확인 필요.

### 1.7 비고

레이어 1은 상위 레이어(분석, 시뮬레이션, 3D)의 모든 데이터 기반이 되므로,  
S1/S2 수준의 이슈는 최우선 해결 대상으로 간주한다.

---

## 2. 레이어 2 – Store Analysis & Analytics

### 2.1 목적 및 범위

#### 목적

- KPI 대시보드 및 분석 페이지에서 표시되는 수치가  
  실제 데이터(또는 통제된 테스트 데이터)와 정확히 일치하는지 검증한다.
- 날짜 범위, 스토어 선택, 세그먼트 필터 등 공통 필터가  
  페이지 내 모든 위젯과 차트에 일관되게 적용되는지 확인한다.

#### 범위 (포함)

- `/` (Dashboard)
- `/footfall-analysis`
- `/traffic-heatmap`
- `/customer-journey`
- `/conversion-funnel`
- `/customer-analysis`
- `/inventory`
- `/product-performance`
- `/analytics`

#### 참조 테이블

- `dashboard_kpis`
- `funnel_metrics`
- `wifi_tracking`
- `inventory_levels`
- `products`
- `ai_recommendations` (대시보드/분석 화면에서 표시되는 범위)

### 2.2 테스트 대상 영역

| ID     | 영역                    | 설명                                                 | 중요도        |
|--------|-------------------------|------------------------------------------------------|---------------|
| L2-F01 | Dashboard KPI           | 방문, 구매, 매출, 전환율 등 요약 KPI                | Critical      |
| L2-F02 | Footfall Analysis       | 시간/요일/이벤트별 유입량 분석                       | High          |
| L2-F03 | Traffic Heatmap         | 존/영역별 히트맵 시각화                              | High          |
| L2-F04 | Customer Journey        | 존 이동 경로 및 체류 시간 분석                       | High          |
| L2-F05 | Conversion Funnel       | Entry→Browse→Fitting→Purchase 퍼널 분석             | Critical      |
| L2-F06 | Customer Analysis       | 고객 세그먼트, LTV, RFM 분석                         | Medium–High   |
| L2-F07 | Inventory Analysis      | 재고 수준, 회전율, 위험 상품 분석                    | High          |
| L2-F08 | Product Performance     | SKU별 성과/기여도 분석                               | High          |

> 주석 (L2-F06 관련 용어)  
> **LTV (Lifetime Value)**: 한 고객이 전체 거래 기간 동안 발생시킬 것으로 예상되는 총 매출(또는 이익)의 크기.  
> **RFM**: Recency, Frequency, Monetary 의 약자로  
> - Recency: 최근 구매 시점 (최근일수록 점수 ↑)  
> - Frequency: 구매 빈도  
> - Monetary: 구매 금액  
> 을 기준으로 고객을 분류하는 분석 방법.

### 2.3 테스트 타입 및 전략

- **수학적 정확성 검증**  
  통제된 테스트 데이터에 대해 SQL/Excel 로 계산한 값과 UI 표시 값이 동일한지 비교한다.

- **필터 일관성 검증**  
  동일 페이지 내 모든 카드, 차트, 테이블이 동일 필터 조건을 공유하는지 검증한다.

- **데이터 부족/부재 상황 검증**  
  데이터가 없거나 적은 경우에도 페이지가 깨지지 않고 적절한 “데이터 없음” 상태를 표시하는지 확인한다.

- **기본 성능 검증**  
  대표 페이지 로드 시간이 과도하게 느리지 않은지 주관적으로 점검한다.

---

### 2.4 테스트 시나리오

#### SCN-L2-01 – Dashboard KPI 수치 일관성

**목적**  
대시보드의 핵심 KPI 수치가 원천 데이터로부터의 수작업 계산 결과와 일치하는지 검증한다.

**사전 조건**

- 스토어 S1 에 대해 3일 정도의 소량 테스트 데이터 준비  
  - 일자별 방문 수, 구매 수, 총 매출이 명확히 계산 가능한 수준  
- 해당 데이터를 기반으로 `dashboard_kpis` 가 수동 또는 집계 함수로 채워진 상태  

**절차**

1. SQL 또는 Excel 을 사용하여 선택한 기간에 대해 다음 값을 계산  
   - 총 방문 수  
   - 총 구매 수  
   - 총 매출  
   - 전환율 (구매 수 / 방문 수)  
2. `/` (Dashboard) 페이지 접속  
3. 날짜 필터를 테스트 기간으로 설정, 스토어 S1 선택  
4. 대시보드 카드 및 요약 차트에서 표시되는 값이 계산값과 일치하는지 확인  
5. 일자별 차트가 있는 경우, 각 날짜별 값도 계산값과 비교  

**통과 기준**

- 카드/차트에 표시되는 핵심 KPI 수치가 수작업 계산 결과와 모두 일치한다.  
- 차이가 있다면 소수점 반올림 정도의 미세한 차이에 한정된다.

---

#### SCN-L2-02 – Footfall 및 Heatmap 정합성

**목적**  
Footfall 분석과 히트맵 시각화(2D 및 3D)가 동일 데이터에 기반하여  
동일한 패턴을 보여주는지 검증한다.

**사전 조건**

- `wifi_tracking` 및 관련 테이블에 단순 패턴 데이터 세팅  
  - 동일 기간 내  
    - Zone Z1: 10건  
    - Zone Z2: 5건  
- Z1, Z2 존 정의가 2D/3D 모두에서 동일하게 사용되는 상태  

**절차**

1. `/footfall-analysis` 접속  
2. 날짜 및 스토어 필터를 테스트 기간/S1 으로 설정  
3. 테이블 또는 차트에서  
   - Z1 = 10, Z2 = 5 로 표시되는지 확인  
4. `/traffic-heatmap` (존재 시) 접속  
   - Z1 이 Z2 보다 더 강한 히트맵(“더 뜨겁게”)으로 표시되는지 확인  
5. `/digital-twin/3d` 접속  
   - Heatmap overlay 활성화  
   - 카메라를 Z1, Z2 위치로 이동  
   - Z1 의 색/강도가 Z2 보다 분명히 강한지 육안 확인  

**통과 기준**

- Z1 > Z2 패턴이 Footfall 분석, 2D Heatmap, 3D Heatmap 의 모든 화면에서 일관되게 나타난다.

---

#### SCN-L2-03 – Conversion Funnel 수학 검증

**목적**  
퍼널 단계별 카운트 및 전환율 계산이 정확히 구현되어 있는지 검증한다.

**사전 조건**

- 단일 일자 기준 퍼널 데이터 세트 구성
  - Entry: 100  
  - Browse: 70  
  - Fitting: 30  
  - Purchase: 20  
- 해당 값이 `funnel_metrics` 또는 이에 상응하는 원천 데이터로 세팅된 상태  

**절차**

1. `/conversion-funnel` 접속  
2. 날짜 필터를 테스트 데이터가 있는 일자로 설정, 스토어 S1 선택  
3. 퍼널 단계별 수치 확인  
   - Entry: 100  
   - Browse: 70  
   - Fitting: 30  
   - Purchase: 20  
4. 전환율 확인  
   - Entry → Browse: 70%  
   - Browse → Fitting: 약 42.86%  
   - Fitting → Purchase: 약 66.67%  
   - Entry → Purchase 전체 전환율: 20%  
5. 차트/레이블에 표시된 수치가 위 값과 일치하는지 확인  

**통과 기준**

- 단계별 수치 및 전환율이 테스트 데이터에서 도출되는 값과 정확히 일치한다.

---

#### SCN-L2-04 – Customer Analysis (RFM/LTV 기본 검증)

**목적**  
간단한 테스트 데이터에 대해 고객 세그먼트(LTV, RFM 기반) 및 LTV 우선순위가 기대와 일치하는지 확인한다.

**사전 조건**

- 테스트 고객 3명  
  - C1: 최근, 자주, 큰 금액 구매 (VIP 가정)  
  - C2: 과거에 자주 구매했으나 최근 활동 없음 (이탈 위험 가정)  
  - C3: 최근 소액 1회 구매 (신규/저가치 가정)  
- 각 고객의 구매 이력을 반영한 `sales` 데이터 세팅  

**절차**

1. `/customer-analysis` 접속  
2. 날짜/스토어 필터를 모든 테스트 고객이 포함되도록 설정  
3. 세그먼트/필터를 이용하여 다음을 확인  
   - C1 이 VIP 성격의 세그먼트에 포함되는지  
   - C2 가 이탈 위험 또는 유사 세그먼트에 포함되는지  
   - C3 가 신규 또는 저가치 세그먼트에 포함되는지  
4. LTV 값이 표시되는 경우  
   - C1 LTV > C2 LTV ≥ C3 LTV 형태의 순서가 유지되는지 확인  

**통과 기준**

- 세그먼트 및 LTV 순서가 테스트 데이터 설계 의도와 일치한다.

---

#### SCN-L2-05 – Inventory 및 Product Performance

**목적**  
재고 지표(재고일수, 위험 표시) 및 상품 성과 지표가 수작업 계산 결과와 일치하는지 검증한다.

**사전 조건**

- 상품 P1, P2 에 대한 통제 데이터  
  - P1: `current_stock = 100`, 평균 일일 수요 = 10 → 재고일수 = 10일  
  - P2: `current_stock = 50`, 평균 일일 수요 = 1 → 재고일수 = 50일  
- 해당 값을 뒷받침하는 `sales` 데이터 구성  

**절차**

1. `/inventory` 접속  
2. 스토어 S1, 테스트 기간으로 필터 설정  
3. 다음 항목 확인  
   - P1 재고일수가 약 10일로 표시되는지  
   - P2 재고일수가 약 50일로 표시되는지  
   - 비즈니스 룰에 따른 재고 위험 표시가 적절히 반영되는지  
4. `/product-performance` 접속  
5. P1, P2 에 대한 매출, 마진, 기여도 값이 엑셀/SQL 수작업 계산 값과 일치하는지 확인  

**통과 기준**

- 재고 및 상품 성과 관련 지표가 모두 수작업 계산 결과와 일치한다.

---

### 2.5 레이어 2 통과/실패 기준

- 통제된 테스트 데이터에 대해 모든 주요 KPI 및 분석 지표가 수작업 계산 결과와 일치한다.  
- 필터 조건이 페이지 내 모든 위젯/차트에 일관되게 적용된다.  
- 비즈니스 의사결정을 오도할 수준의 계산 오류가 존재하지 않는다.

### 2.6 버그 분류 및 예상 핫스팟

#### Severity

- S1: 잘못된 KPI/퍼널 값이 표시되어 사용자를 심각하게 오도하는 수준.  
- S2: 특정 필터/조건에서만 값이 잘못되거나 차트가 깨지는 수준.  
- S3: 라벨, 반올림, 시각 표현 등 비핵심 문제.  
- S4: 순수한 시각적/미세한 문제.

#### 예상 핫스팟

- 타임존(Asia/Seoul) 처리 오류로 인한 날짜 하루 밀림/당김.  
- 퍼널 계산 시 분모 설정 오류.  
- 여러 테이블 조인 시 중복 카운트 또는 누락 발생.  
- 잘못된 조인 조건으로 인한 데이터 혼합.

### 2.7 비고

레이어 2는 사용자에게 직접 노출되는 숫자를 다루므로,  
작은 불일치도 신뢰도에 큰 영향을 줄 수 있다.  
테스트 시 숫자 검증을 우선순위 높게 수행한다.

---

## 3. 레이어 3 – Simulation & AI

### 3.1 목적 및 범위

#### 목적

- 레이아웃, 가격, 수요, 추천 등 모든 시뮬레이션 타입이  
  **시나리오 생성 → AI 추론 호출 → 결과 저장 → UI 표시**  
  전체 플로우 기준으로 정상 동작하는지 검증한다.
- 파라미터 오류, AI/Edge Function 실패, 응답 포맷 이상 등 오류 상황에서  
  UI가 깨지지 않고 명확한 오류 메시지를 제공하는지 검증한다.

#### 범위 (포함)

- 페이지
  - `/simulation/hub`
  - `/simulation/layout`
  - `/simulation/pricing`
  - `/simulation/demand`
  - `/simulation/recommendation`
- 테이블
  - `scenarios`
  - `simulation_results`
  - `ai_recommendations`
  - `ai_scene_analysis`
- Edge Functions
  - `advanced-ai-inference`
  - `generate-ai-recommendations`

### 3.2 테스트 대상 영역

| ID     | 영역                        | 설명                                               | 중요도       |
|--------|-----------------------------|----------------------------------------------------|--------------|
| L3-F01 | Simulation Hub              | 시나리오 목록 및 상태 요약                        | High         |
| L3-F02 | Layout Simulation           | 레이아웃 변경에 따른 KPI 영향 시뮬레이션          | Critical     |
| L3-F03 | Pricing Simulation          | 가격 변경에 따른 수요/매출 시뮬레이션             | Critical     |
| L3-F04 | Demand Forecast             | 향후 수요 예측                                     | High         |
| L3-F05 | Inventory Optimization      | 최적 재고 수준 계산                                | High         |
| L3-F06 | Recommendation Strategy     | 추천 전략 및 A/B 테스트 제안                       | Medium–High  |
| L3-F07 | AI Recommendations          | 추천 카드 표시                                     | High         |
| L3-F08 | AI Scene Analysis           | 3D 씬 분석 결과                                    | Medium       |

### 3.3 테스트 타입 및 전략

- **기능 플로우 테스트**  
  시나리오 생성, 실행, 결과 조회까지 전체 플로우 검증.

- **오류 처리 테스트**  
  유효하지 않은 파라미터, AI/Edge Function 실패, 타임아웃 등의 상황에서  
  적절한 오류 메시지와 복구 가능 상태를 제공하는지 검증.

- **데이터 정합성 테스트**  
  `scenarios`, `simulation_results`, `ai_recommendations` 등 저장 데이터 간  
  참조 관계 및 상태가 일관되는지 확인.

---

### 3.4 테스트 시나리오 (대표 예시)

#### SCN-L3-01 – Layout Simulation 엔드투엔드

**목적**  
레이아웃 시뮬레이션 시나리오가 생성, 실행, 저장, UI 표시까지 엔드투엔드로 정상 동작하는지 검증한다.

**사전 조건**

- 스토어 S1 에 대해 기본 KPI(하루 평균 매출, 방문, 전환율 등)가 조회 가능한 상태  
- 간단한 Layout 파라미터 (존 면적 변경, 집기 이동 등) 설계  

**절차**

1. `/simulation/layout` 접속  
2. 새 시나리오 생성  
   - 시나리오 이름 및 설명 입력  
   - 스토어 S1 선택  
3. Layout 파라미터 입력  
   - 예: 특정 존 면적 20% 확대, 집기 위치 변경 등  
4. 시뮬레이션 실행 버튼 클릭  
5. 진행 중  
   - 로딩 표시가 나타났다 사라지는지 확인  
6. 완료 후  
   - Before/After KPI (매출, 유입, 전환율 등)가 화면에 표시되는지 확인  
   - 요약 인사이트 텍스트가 표시되는 경우 내용 확인  
7. Supabase 에서 확인  
   - `scenarios` 테이블에 `scenario_type = 'layout'` 인 새 레코드가 생성되었고, `status` 가 성공 상태로 기록되어 있는지 확인  
   - `simulation_results` 테이블에 해당 `scenario_id` 를 참조하는 레코드가 존재하며, 결과 데이터가 저장되어 있는지 확인  

**통과 기준**

- UI 상 시뮬레이션이 오류 없이 완료된다.  
- Before/After KPI 가 일관성 있게 표시된다.  
- `scenarios` 및 `simulation_results` 의 데이터가 서로 일치하는 참조 관계를 가진다.

---

#### SCN-L3-02 – Pricing & Demand 시뮬레이션 정합성

**목적**  
가격 및 수요 시뮬레이션이 각각 정상 수행되고,  
통제된 상품 세트에 대해 서로 모순되지 않는 결과를 제공하는지 검증한다.

**사전 조건**

- 통제된 히스토리 데이터를 가진 상품 세트 구성  
- 테스트 목적상 “가격 인하 → 수요 증가” 등의 기대 행동 정의  

**절차**

1. `/simulation/pricing` 접속  
2. 새로운 가격 시뮬레이션 시나리오 생성  
   - 대상 상품 및 새로운 가격 입력  
3. 시뮬레이션 실행  
4. 예측된 수요 변화 및 매출 변화가 화면에 표시되는지 확인  
5. `/simulation/demand` 접속  
6. 동일(또는 연관된) 상품/기간에 대해 수요 예측 시나리오 생성  
7. 시뮬레이션 실행  
8. 두 결과를 상위 수준에서 비교  
   - 테스트 설계상 기대와 정면으로 모순되는 결과(예: 가격 인하인데 수요 급감)가 발생하지 않는지 확인  

**통과 기준**

- 두 시뮬레이션 타입 모두 정상 완료 및 결과 저장.  
- 통제된 시나리오 내에서 결과가 논리적으로 일관된 방향성을 가진다.

---

#### SCN-L3-03 – Recommendation Strategy 및 AI Recommendations

**목적**  
추천 전략 시나리오 실행 시 `ai_recommendations` 레코드가 생성되고,  
UI에서 추천 카드로 표시되는지 검증한다.

**사전 조건**

- 특정 카테고리를 자주 구매하는 고객 세트 등 간단한 패턴 데이터 구성  

**절차**

1. `/simulation/recommendation` 접속  
2. 새 추천 전략 시나리오 생성  
   - 타깃 세그먼트 및 전략 타입 선택  
3. 시뮬레이션 실행  
4. 완료 후 Supabase 확인  
   - `ai_recommendations` 테이블에 스토어 S1 에 대한 신규 레코드가 생성되었는지 확인  
5. 대시보드 또는 추천 전용 페이지 접속  
6. 추천 카드 목록에서 `ai_recommendations` 레코드 내용과 일치하는 추천 항목이 표시되는지 확인  

**통과 기준**

- 추천 전략 시나리오가 정상 완료된다.  
- `ai_recommendations` 레코드가 생성되며, UI 추천 카드와 내용이 일치한다.

---

#### SCN-L3-04 – AI 오류 및 타임아웃 처리

**목적**  
AI 및 Edge Function 실패 상황에서 UI가 안정적으로 동작하며,  
명확한 오류 메시지를 표시하는지 검증한다.

**사전 조건**

- 비정상 파라미터 사용, 테스트 플래그, 잘못된 설정 등으로 의도적으로 실패를 유도할 수 있는 환경  

**절차**

1. 각 시뮬레이션 타입(레이아웃, 가격, 수요, 추천)에 대해  
   - 의도적으로 유효하지 않은 파라미터 또는 극단적인 값을 사용하는 시나리오를 생성  
   - 시뮬레이션 실행  
2. 동작 확인  
   - UI 에서 시뮬레이션 실패를 알리는 오류 메시지가 표시되는지 확인  
   - 무한 로딩이나 화면 멈춤 현상이 발생하지 않는지 확인  
   - 내부 스택트레이스, SQL, 시스템 경로 등 기술적 상세가 노출되지 않는지 확인  
3. Supabase 확인  
   - 실패한 시나리오에 대해 `scenarios.status` 가 실패 상태로 저장되는지 확인  
   - `simulation_results` 에 불완전한 레코드가 남지 않는지, 구현 정책에 따라 확인  

**통과 기준**

- 실패 상황에서도 UI가 깨지지 않고 복구 가능한 상태를 유지한다.  
- 오류 메시지가 명확하며 내부 구현 상세를 노출하지 않는다.  
- 실패한 시나리오가 올바르게 실패 상태로 표시되고, 저장 데이터 정합성이 유지된다.

---

### 3.5 레이어 3 통과/실패 기준

- 각 시뮬레이션 타입별로 최소 1건 이상의 정상 엔드투엔드 시나리오가 수행된다.  
- 오류 상황에서 UI 크래시 없이 오류 메시지가 표시되고, 애플리케이션 사용이 계속 가능하다.  
- 저장 데이터(`scenarios`, `simulation_results`, `ai_recommendations` 등)의 참조 관계와 상태가 일관된다.

### 3.6 버그 분류 및 예상 핫스팟

#### Severity

- S1: 특정 시뮬레이션 타입이 전혀 실행되지 않거나 결과 조회가 불가능한 수준.  
- S2: 결과/상태가 불일치하여 사용자가 시뮬레이션 결과를 신뢰하기 어려운 수준.  
- S3: 일부 표시 필드, 텍스트, 레이아웃 등의 비핵심 문제.  
- S4: 경미한 시각적 문제.

#### 예상 핫스팟

- `advanced-ai-inference` 파라미터 유효성 검증 누락.  
- 외부 AI 응답 포맷 변경 또는 필드 누락에 대한 방어 로직 부족.  
- 시뮬레이션 실행 후 화면이 이전 데이터(캐시)를 계속 표시하는 문제.

### 3.7 비고

레이어 3은 상위 의사결정 기능에 직결되므로,  
레이어 1·2 데이터 품질과의 연계성을 고려하여 원인 분석을 수행한다.

---

## 4. 레이어 4 – Digital Twin 3D

### 4.1 목적 및 범위

#### 목적

- `store_scenes` 의 `SceneRecipe` 기반으로 3D 디지털 트윈 씬이 정상적으로 로딩되는지 검증한다.  
- Heatmap, 동선, 존 경계, 상품 마커 등 오버레이가 분석 데이터와 공간적으로 일관되게 표시되는지 검증한다.

#### 범위 (포함)

- `/digital-twin/3d` 페이지  
- `store_scenes` (SceneRecipe)  
- `wifi_tracking` (히트맵/동선용)  
- 필요한 경우 `graph_entities` 의 3D 메타데이터 필드  

### 4.2 테스트 대상 영역

| ID     | 영역                     | 설명                                        | 중요도  |
|--------|--------------------------|---------------------------------------------|---------|
| L4-F01 | Scene Loading            | `store_scenes` 기반 씬 로딩                | Critical|
| L4-F02 | Model Layers             | Base/가구/상품 레이어 렌더링               | High    |
| L4-F03 | Camera & Lighting        | 초기 카메라/조명 프리셋                     | High    |
| L4-F04 | Heatmap Overlay          | WiFi/footfall 기반 히트맵                   | Critical|
| L4-F05 | Path Overlay             | 고객 동선 시각화                            | High    |
| L4-F06 | Zone Boundary Overlay    | 존 경계 시각화                              | High    |
| L4-F07 | Product Info Overlay     | 상품 정보 마커/툴팁                         | Medium  |
| L4-F08 | Performance              | 중간 규모 씬에서의 기본 성능                | Medium  |

### 4.3 테스트 타입 및 전략

- 기능/시각화 테스트  
  씬 로딩, 오버레이 렌더링 여부 및 기본 동작 확인.

- 공간 정합성 테스트  
  2D 분석 결과(히트맵, 존)와 3D 오버레이의 위치/강도가 일치하는지 검증.

- 강건성 테스트  
  씬 없음, 오버레이 데이터 없음 등의 경우에도 UI가 안정적으로 동작하는지 확인.

- 기본 성능 테스트  
  중간 규모 씬 기준으로 카메라 이동/회전 시 사용 가능한 수준의 반응성을 갖는지 확인.

---

### 4.4 테스트 시나리오 예시

#### SCN-L4-02 – 2D vs 3D Heatmap 정합성

**목적**  
3D Heatmap Overlay 의 강도가 2D Heatmap/Footfall 데이터와 동일한 패턴을 보이는지 검증한다.

**사전 조건**

- `wifi_tracking` 에 단순 패턴 데이터 구성  
  - 동일 기간 내  
    - Z1: 20건  
    - Z2: 5건  
- Z1, Z2 존 정의가 2D/3D 에서 동일하게 사용되는 상태  

**절차**

1. `/footfall-analysis` 또는 `/traffic-heatmap` 접속  
2. 테스트 기간 및 스토어 S1 으로 필터 설정  
3. Footfall 또는 Heatmap 데이터에서  
   - Z1 이 Z2 보다 높은 값 또는 강도로 표시되는지 확인  
4. `/digital-twin/3d` 접속  
5. Heatmap overlay 활성화  
6. 카메라를 Z1, Z2 위치가 잘 보이도록 이동  
7. Z1 이 Z2 보다 분명히 높은 강도로 렌더링되는지 확인  

**통과 기준**

- Z1 > Z2 상대적인 강도 패턴이 2D/3D 모두에서 동일하게 나타난다.  
- 렌더링 오류 또는 명백한 위치 어긋남이 없어야 한다.

---

### 4.5 레이어 4 통과/실패 기준

- 일반적인 매장에 대한 씬이 오류 없이 로딩된다.  
- 오버레이가 분석 데이터와 공간적으로 일치하며, 사용자를 오도할 정도의 큰 오차가 없다.  
- 중간 규모 씬에서 기본적인 상호작용(회전/줌 등)이 사용 불가능한 수준으로 느리지 않다.

### 4.6 버그 분류 및 예상 핫스팟

#### Severity

- S1: `/digital-twin/3d` 페이지가 사용 불가능하거나 씬이 전혀 로딩되지 않는 수준.  
- S2: 오버레이가 데이터와 심각하게 어긋나 잘못된 공간 정보를 전달하는 수준.  
- S3/S4: 시각적인 경미한 문제, 카메라 초기 위치/조명 등 비핵심 이슈.

#### 예상 핫스팟

- `SceneRecipe` 버전 변경에 따른 파싱 오류.  
- GLB 모델의 축/스케일/회전 불일치로 인한 위치 어긋남.  
- overlay 데이터 변환 로직(좌표계 변환) 오류.

### 4.7 비고

레이어 4는 시각적 의존성이 크므로,  
테스트 시 스크린샷을 함께 수집하는 것이 분석에 유용하다.

---

## 5. 레이어 5 – 공통 레이어 (Authentication, RLS, Error Handling, Basic Performance)

> 주석  
> **RLS (Row Level Security)**: `user_id` 와 같은 조건에 따라  
> 각 사용자에게 허용된 행만 조회/조작하도록 제한하는 데이터베이스 보안 정책을 의미한다.

### 5.1 목적 및 범위

#### 목적

- 인증, 권한, RLS, 공통 오류 처리, 기본 성능 등  
  전 레이어에 공통적으로 영향을 주는 요소들이 안전하고 일관되게 동작하는지 검증한다.

#### 범위 (포함)

- 로그인/로그아웃/세션 유지 흐름  
- `ProtectedRoute` 를 통한 보호 페이지 접근 제어  
- 모든 사용자 스코프 테이블의 RLS 정책  
- 공통 에러 알림 및 복구 동작  
- 대표 페이지의 기본 성능(주관적 확인)  

### 5.2 테스트 대상 영역

| ID     | 영역                | 설명                                        | 중요도  |
|--------|---------------------|---------------------------------------------|---------|
| L5-F01 | Authentication      | 로그인, 로그아웃, 세션 관리                 | Critical|
| L5-F02 | ProtectedRoute      | 비로그인 사용자의 보호 페이지 접근 차단    | Critical|
| L5-F03 | Row Level Security  | 사용자/조직 단위 데이터 격리                | Critical|
| L5-F04 | Error Handling      | 공통 오류 메시지 및 토스트                  | High    |
| L5-F05 | Basic Performance   | 대표 화면의 기본 로딩/반응 속도             | Medium  |

---

### 5.3 테스트 시나리오

#### SCN-L5-01 – Authentication & ProtectedRoute

**목적**  
로그인하지 않은 사용자가 보호 페이지에 접근할 수 없고,  
로그아웃 후에는 세션이 완전히 종료되는지 검증한다.

**사전 조건**

- 유효한 사용자 계정 A

**절차**

1. 로그인되지 않은 상태에서 `/stores`, `/data-import` 등 보호 페이지 URL 에 직접 접근  
   - `/auth` 또는 로그인 페이지로 리다이렉트되는지 확인  
2. 계정 A 로 로그인  
3. 주요 보호 페이지에 순차적으로 접근하여 정상적으로 접근 가능한지 확인  
4. 로그아웃 수행  
5. 브라우저 뒤로가기를 사용하여 보호 페이지로 돌아가려고 시도  
   - 유효한 세션 없이 다시 접근이 허용되지 않는지 확인  

**통과 기준**

- 보호 페이지는 로그인 없는 상태에서 접근할 수 없다.  
- 로그아웃 후에는 뒤로가기 등을 통해 보호 페이지가 재사용되지 않는다.

---

#### SCN-L5-02 – 멀티 유저 RLS 검증

**목적**  
RLS 정책이 서로 다른 사용자 간 데이터 격리를 정상적으로 보장하는지 검증한다.

**사전 조건**

- 사용자 계정 A, B  
- 계정 A  
  - 스토어 S1 및 관련 데이터 (임포트, 시뮬레이션, 씬 등)  
- 계정 B  
  - 스토어 S2 및 관련 데이터 (S1과 구분되는 별도 데이터 세트)  

**절차**

1. 계정 A 로 로그인  
2. `/stores`, `/data-import`, `/simulation/*`, `/digital-twin/3d` 등 주요 페이지를 순회  
   - S1 및 계정 A 와 관련된 데이터만 표시되는지 확인  
3. 로그아웃  
4. 계정 B 로 로그인  
5. 동일한 페이지들을 순회  
   - S2 및 계정 B 와 관련된 데이터만 표시되는지 확인  
6. (테스트 환경에서 가능한 경우) Supabase SQL 콘솔을 통해  
   - 각 계정 컨텍스트로 `SELECT * FROM stores` 와 같은 단순 쿼리 실행  
   - 각 계정에서 자기 소유 데이터만 조회되는지 확인  

**통과 기준**

- 계정 A 의 데이터가 계정 B 세션에서 보이지 않고, 그 반대도 마찬가지이다.  
- 테스트한 모든 테이블에서 RLS 정책이 일관되게 적용된다.

---

#### SCN-L5-03 – 공통 오류 처리 검증

**목적**  
백엔드 API 및 Edge Function 오류가 사용자에게  
명확하고 일관된 메시지로 표시되며, UI가 계속 사용 가능한 상태를 유지하는지 검증한다.

**사전 조건**

- 비정상 파라미터, 비활성화된 설정, 테스트 플래그 등을 통해 의도적으로 오류를 발생시킬 수 있는 환경  

**절차**

1. 레이어 1~4 의 대표 기능들(임포트, 시뮬레이션, 외부 동기화 등)에 대해  
   한 번 이상 오류 상황을 발생시키는 입력을 수행  
2. UI 동작 확인  
   - 오류 알림 또는 토스트가 표시되는지 확인  
   - 메시지 내용이 사용자가 이해 가능한 수준인지 확인  
3. 오류 발생 후에도  
   - 페이지 로딩/상호작용이 가능한지  
   - 다른 기능 사용에 문제가 없는지 확인  

**통과 기준**

- 오류 발생 시 사용자에게 적절한 알림이 제공된다.  
- 내부 스택트레이스, SQL, 시스템 경로 등 기술적 상세가 노출되지 않는다.  
- 애플리케이션이 오류 이후에도 정상적으로 계속 사용 가능하다.

---

### 5.4 레이어 5 통과/실패 기준

- 보호 페이지 접근 제어가 올바르게 동작한다.  
- RLS 로 인해 사용자 간 데이터 누출이 발생하지 않는다.  
- 오류 처리 로직이 일관되며, 내부 구현 상세를 노출하지 않는다.  
- 일반적인 워크플로우 기준으로 심각한 성능 문제는 관찰되지 않는다.

### 5.5 버그 분류 및 예상 핫스팟

#### 심각성

- S1: 인증 또는 RLS 실패로 인해 권한 없는 데이터 접근/누출이 가능한 수준.  
- S2: 오류 처리 실패로 애플리케이션이 멈추거나 사용 불가능해지는 수준.  
- S3/S4: 오류 메시지 문구, 성능 경미 이슈 등 비핵심 문제.

#### 예상 핫스팟

- 신규 테이블 생성 후 RLS 정책 누락.  
- Edge Function 호출 시 auth 컨텍스트 미전달.  
- 일부 페이지에서 인증 여부 검증 누락으로 인한 직접 접근 허용.

### 5.6 비고

공통 레이어의 S1 이슈는 보안 및 신뢰성 측면에서 치명적이므로  
최우선 해결 대상으로 분류한다.

---
